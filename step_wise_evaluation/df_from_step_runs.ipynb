{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the absolute path of the current script\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Move up directories until we find the project's root (assumed to have a .git folder or another marker)\n",
    "while (\n",
    "    not os.path.exists(os.path.join(current_path, '.git'))\n",
    "    and os.path.dirname(current_path) != current_path\n",
    "):\n",
    "    current_path = os.path.dirname(current_path)  # Move one level up\n",
    "\n",
    "# Change the working directory to the detected root\n",
    "os.chdir(current_path)\n",
    "\n",
    "print(f'Changed working directory to: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory to search\n",
    "base_dir = 'logs/step_tasks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions for filtering subfolders and JSON files\n",
    "subfolder_pattern = re.compile(r'step_\\d+_openhands_\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}')\n",
    "json_file_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}_metrics\\.json$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store data\n",
    "data_list = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    # Check if the current directory matches the required subfolder pattern\n",
    "    if not subfolder_pattern.search(os.path.basename(root)):\n",
    "        continue  # Skip directories that donâ€™t match\n",
    "\n",
    "    for file in files:\n",
    "        if json_file_pattern.match(file):  # Match JSON files\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    json_data = json.load(f)\n",
    "\n",
    "                    # Flatten JSON and add metadata\n",
    "                    # json_data[\"source_file\"] = file\n",
    "                    # json_data[\"source_folder\"] = os.path.basename(root)\n",
    "\n",
    "                    data_list.append(json_data)\n",
    "\n",
    "            except (json.JSONDecodeError, OSError) as e:\n",
    "                print(f'Error reading {file_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "for col in cols:\n",
    "    print(f\"'{col}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[\n",
    "    [\n",
    "        'agent_name',\n",
    "        'difficulty',\n",
    "        'task_id',\n",
    "        'query',\n",
    "        'final_answer',\n",
    "        'success',\n",
    "        'checkpoint_provided_ratio',\n",
    "        'checkpoint_expected_ratio',\n",
    "        'checkpoints',\n",
    "        'model_name',\n",
    "        'screenshots',\n",
    "        'model_calls',\n",
    "        'input_tokens',\n",
    "        'output_tokens',\n",
    "        'total_tokens',\n",
    "        'full_runtime',\n",
    "        'text_model',\n",
    "        'vision_model',\n",
    "        'multi_agent',\n",
    "        'timestamp',\n",
    "    ]\n",
    "]\n",
    "# df_filtered sort by difficulty and task_id\n",
    "df_filtered = df_filtered.sort_values(by=['agent_name', 'difficulty', 'task_id'])\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.agent_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered to csv\n",
    "df_filtered.to_csv('logs/step_tasks/step_tasks.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of stepwise tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate per 'difficulty'\n",
    "\n",
    "# add column \"number of tasks\" how many tasks per difficulty were used to calculate the mean\n",
    "df_summary = (\n",
    "    df_filtered.groupby(['model_name', 'agent_name', 'difficulty'])\n",
    "    .agg(\n",
    "        success=('success', 'mean'),\n",
    "        checkpoint_provided_ratio=('checkpoint_provided_ratio', 'mean'),\n",
    "        checkpoint_expected_ratio=('checkpoint_expected_ratio', 'mean'),\n",
    "        model_calls=('model_calls', 'mean'),\n",
    "        total_tokens=('total_tokens', 'mean'),\n",
    "        full_runtime=('full_runtime', 'mean'),\n",
    "        number_of_tasks=('task_id', 'size'),\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "# rename \"success\" column to \"success_rate\"\n",
    "df_summary.rename(columns={'success': 'success_rate'}, inplace=True)\n",
    "# append \"_mean\" to all columns that are mean values\n",
    "df_summary.columns = [\n",
    "    f'{col}_mean' if col != 'number_of_tasks' else col for col in df_summary.columns\n",
    "]\n",
    "df_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv('logs/step_tasks/step_tasks_summary.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(checkpoints_path, 'r', encoding='utf-8') as file:\n",
    "    return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = 'step_wise_evaluation/steps_definition.json'  # Update with actual checkpoint file path\n",
    "with open(checkpoints_path, 'r', encoding='utf-8') as file:\n",
    "    checkpoints_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through checkpoints_data and print the keys:\n",
    "for key in checkpoints_data.keys():\n",
    "    (print(key),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all keys and print the \"entries\"\n",
    "for key in checkpoints_data.keys():\n",
    "    print(key)\n",
    "    for entry in checkpoints_data[key]['entries']:\n",
    "        print(f\"{entry['query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every key in checkpoints_data, print \"goals\"\n",
    "for key in checkpoints_data.keys():\n",
    "    print(key)\n",
    "    print(checkpoints_data[key]['goal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
